{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a73077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "import chromadb\n",
    "import gradio as gr\n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"your_actual_token_here\"\n",
    "if not os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]:\n",
    "    raise ValueError(\"HUGGINGFACEHUB_API_TOKEN is not set in the environment variables.\")\n",
    "\n",
    "def initialize_embeddings():\n",
    "    model_identifier = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "    return HuggingFaceEmbeddings(model_name=model_identifier)\n",
    "\n",
    "def process_and_embed_docs(dir_path, hf_model):\n",
    "    chroma_instance = chromadb.Client()\n",
    "    doc_loader = DirectoryLoader(dir_path)\n",
    "    loaded_docs = doc_loader.load()\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "    split_docs = splitter.split_documents(loaded_docs)\n",
    "    database = Chroma.from_documents(documents=split_docs, embedding=hf_model)\n",
    "    return database\n",
    "\n",
    "def concatenate_documents(document_list):\n",
    "    combined_content = \"\".join([doc.page_content for doc in document_list])\n",
    "    return combined_content\n",
    "\n",
    "hf_model = initialize_embeddings()\n",
    "example_path = r\"PATH_TO_YOUR_DATASET_DIRECTORY\"\n",
    "vector_database = process_and_embed_docs(example_path, hf_model)\n",
    "\n",
    "def query_llama2_EP(context, query, endpoint_url):\n",
    "    template = f\"\"\"\n",
    "    <s>[INST] <<SYS>>\n",
    "    Confine your answer within the given context and do not generate the next context.\n",
    "    Answer truthful answers, don't try to make up an answer.\n",
    "    <</SYS>>\n",
    "    Context: {context}\n",
    "    Question: {query}\n",
    "    Answer: \"\"\"\n",
    "    \n",
    "    headers = {\n",
    "        'Authorization': 'YOUR_AUTHORIZATION_KEY_HERE',\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "    \n",
    "    config = {\n",
    "        \"max_new_tokens\": 200,\n",
    "        \"temperature\": 0.01,\n",
    "        \"return_full_text\": False,\n",
    "        \"early_stopping\": False,\n",
    "        \"stop_sequence\": \"***\",\n",
    "        \"do_sample\": True,\n",
    "        \"top_p\": 0.9,\n",
    "        \"num_return_sequences\": 1\n",
    "    }\n",
    "    \n",
    "    json_data = {\n",
    "        'inputs': template,\n",
    "        'parameters': config\n",
    "    }\n",
    "    \n",
    "    response = requests.post(endpoint_url, headers=headers, json=json_data)\n",
    "    result = response.text.split(\"\\\":\\\"\")[1].split(\"\\\"}]\")[0]\n",
    "    return result\n",
    "\n",
    "def process_query(query):\n",
    "    retrieved_docs = vector_database.search_similar(query)\n",
    "    combined_context = concatenate_documents(retrieved_docs)\n",
    "    answer = query_llama2_EP(combined_context, query, 'YOUR_ENDPOINT_URL_HERE')\n",
    "    return answer.replace(\"\\\\n\", \"\\n\")\n",
    "\n",
    "alula_smart_speaker = gr.Interface(\n",
    "    fn=process_query,\n",
    "    inputs=\"textbox\",\n",
    "    outputs=\"textbox\",\n",
    "    title=\"Smart Speaker\"\n",
    ")\n",
    "\n",
    "alula_smart_speaker.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
